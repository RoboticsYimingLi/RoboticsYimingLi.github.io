<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="theme" content="hugo-academic" />
        <meta name="generator" content="Hugo 0.19" />
        <meta name="author" content="Yiming Li" />
        <meta name="description" content="Bachelor of Mechanical Engnieering" />
        <link rel="stylesheet" href="/css/highlight.min.css" />
        <link rel="stylesheet" href="/css/bootstrap.min.css" />
        <link rel="stylesheet" href="/css/font-awesome.min.css" />
        <link rel="stylesheet" href="/css/academicons.min.css" />
        <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono" />
        <link rel="stylesheet" href="/css/hugo-academic.css" />
        <link rel="alternate" href="https://tpbull.github.io/index.xml" type="application/rss+xml" title="Yiming Li's Website" />
        <link rel="feed" href="https://tpbull.github.io/index.xml" type="application/rss+xml" title="Yiming Li's Website" />
        <link rel="icon" type="image/jpeg" href="/img/nyu.jpeg" />
        <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png" />
        <link rel="canonical" href="https://tpbull.github.io/" />
        <title>Yiming Li's Website</title>
        <script>var _hmt = _hmt || []; (function() {
                var hm = document.createElement("script");
                hm.src = "https://hm.baidu.com/hm.js?c83bf8b7e066e7c41af36a85a5651bf2";
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(hm, s);
            })();</script>
    </head>

    <body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">
        <nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
            <div class="container">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/">Yiming Li's Website</a></div>
                <div class="collapse navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li class="nav-item">
                            <a href="/#about" data-target="#about">
                                <span>About me</span></a>
                        </li>
						<li class="nav-item">
                            <a href="/#Research" data-target="#Research">
                                <span>Research Highlights</span></a>
                        </li>
                        <li class="nav-item">
                            <a href="/#Publications" data-target="#Publications">
                                <span>Publications</span></a>
                        </li>
<!--						<li class="nav-item">-->
<!--                            <a href="/#Preprints" data-target="#Preprints">-->
<!--                                <span>Preprints</span></a>-->
<!--                        </li>-->
						<li class="nav-item">
                            <a href="/#Patents" data-target="#Patents">
                                <span>Patents</span></a>
                        </li>
                        </li>
						<li class="nav-item">
                            <a href="/#Awards" data-target="#Awards">
                                <span>Awards</span></a>
                        </li>
						<li class="nav-item">
                            <a href="/#Coursework" data-target="#Coursework">
                                <span>Coursework</span></a>
                        </li>
                        <li class="nav-item">
                            <a href="/#contact" data-target="#contact">
                                <span>Contact</span></a>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
        <span id="homepage" style="display: none"></span>
        <section id="about" class="home-section">
            <div class="container">
                <div class="row" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                    <div class="col-xs-12 col-md-4">
                        <div id="profile">
                            <div class="portrait" itemprop="image" style="background-image: url('/img/yiming.jpeg');"></div>
                            <div class="portrait-title">
                                <h2 itemprop="name">Yiming Li</h2>
                                <h3 itemprop="jobTitle">Dean's PhD Fellow</h3>
                                <h3 itemprop="worksFor">New York University<br>NYC, USA</h3>
                            </div>
                            <p>
                                <a href="https://github.com/RoboticsYimingLi"><i class="fa fa-github fa-2x"></i></a> &nbsp  
                                <a href="https://scholar.google.com.hk/citations?user=i_aajNoAAAAJ&hl=zh-CN"><i class="ai ai-google-scholar ai-2x"></i></a> &nbsp  
                                <a href="https://scholar.google.com.hk/citations?user=i_aajNoAAAAJ&hl=zh-CN"><i class="ai ai-cv ai-2x"></i></a> &nbsp  
                                <a href="https://www.researchgate.net/profile/Yiming-Li-37"><i class="ai ai-researchgate ai-2x"></i></a> 
                            </p>
                        </div>
                    </div>
                    <div class="col-xs-12 col-md-8" itemprop="description">
                        <h1 id="biography">About me</h1>
                        <p> I am a second-year PhD student in <a href="https://ai4ce.github.io/">AI4CE Lab</a> at <a href="https://www.nyu.edu/">New York University (NYU)</a> with <b>Dean's PhD Fellowship</b>. Prior to NYU, I received my bachelor degree in mechanical engineering from <a href="https://en.tongji.edu.cn/">Tongji University (TJU)</a> with the highest honor <b>Academic Star</b>, where I work in <a href="https://vision4robotics.github.io/">Vision4robotics Group</a>.
                        <p> My research lies in the intersection of robotics, computer vision, and machine learning, whose goal is to <I>promote the robotics autonomy by advancing robot perception and learning capability in complex scenarios</I>. Currently, my research directions are: 1) <b>multi-agent</b> perception and learning, 2) <b>adversarially robust</b> perception and safe AI, 3) <b>egocentric</b> perception and prediction, and 4) <b>lightweight</b> perception for resource-constrained robots. The main applications of my research lie in <b>autonomous driving</b>, <b>construction automation</b>, and <b>human-robot interaction</b>.</p>
                    </div>

                    <div class="col-md-12">
                        <div class="col-sm-4">
                            <h3>Education</h3>
                            <ul class="ul-edu fa-ul">
                                <li>
                                    <i class="fa-li fa fa-graduation-cap"></i>
                                    <div class="description">
                                        <p class="course">PhD Student in Robotics
                                            <br />Sept. 2020 -- Now</p>
                                        <p class="institution">New York University, USA</p></div>
                                </li>
                                <li>
                                    <i class="fa-li fa fa-graduation-cap"></i>
                                    <div class="description">
                                        <p class="course">B.Eng. of Mechanical Engnieering
                                            <br />Sept. 2015 -- July 2020</p>
                                        <p class="institution">Tongji University, Shanghai</p></div>
                                </li>
								                                <li>
                                    <i class="fa-li fa fa-graduation-cap"></i>
                                    <div class="description">
                                        <p class="course">High School Student
                                            <br />Sept. 2012 -- Jun. 2015</p>
                                        <p class="institution">Taiyuan No.5 Middle Schoole</p></div>
                                </li>
                            </ul>
                        </div>
			<div class="col-sm-8">
                            <h3>News</h3>
<!--                            <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:##67c077;height:8px" />-->
                            <ul class="ul-interests">
				<li>
                                    09/2021: One paper is accepted at NeurIPS 2021.                             
                                </li>
				<li>
                                    09/2021: Arrive <b>New York City</b> and finish my remote PhD study year!                             
                                </li>
				<li>
                                    07/2021: Two papers are accepted at ICCV 2021 <b>including 1 oral</b>.                           
                                </li>
				<li>
                                    07/2021: One paper is accepted at IROS 2021.                           
                                </li>
				<li>
                                    06/2021: Attend ICRA 2021 at <b>Xi'an, China</b>!                           
                                </li>
				<li>
                                    02/2021: One paper is accepted at ICRA 2021.                           
                                </li>
<!--				<li>-->
<!--                                    09/2020: Start NYU PhD program remotely, awarded <b>Dean's PhD Fellowship</b>.                           -->
<!--                                </li>-->
				<li>
                                    07/2020: Four papers are accepted at IROS 2020.                           
                                </li>
				<li>
                                    02/2020: One paper is accepted at CVPR 2020.                               
                                </li>
				<li>
                                    01/2020: Two papers are accepted at ICRA 2020.
                                </li>
                                <li>
                                    11/2019: Attend IROS 2019 at <b>Macau, China</b>!   
                                </li>
                                <li>
                                    10/2019: Attend ICCV 2019 at <b>Seoul, South Korea</b>!   
                                </li>
<!--                                <li>-->
<!--                                    07/2019: One paper is accepted at ICCV 2019.-->
<!--                                </li>-->
<!--                                <li>-->
<!--                                    06/2019: One paper is accepted at IROS 2019.-->
                                </li>
<!--								<li>-->
<!--                                        <p class="institution">07/2018: I join the <a href="https://vision4robotics.github.io/">Vision4robotics Group</a>, enjoy the academic journey!</p>-->
<!--                                </li>-->


                        </div>                       
                    </div>
                </div>
            </div>

<!--	    <section id="Research" class="home-section">-->
<!--            <div class="container">-->
<!--                <div class="row">-->
<!--                    <div class="col-xs-12 col-md-6 section-heading">-->
<!--                        <h1>Research Highlights</h1></div>-->
<!--                    <div class="col-xs-12">-->
<!--                        <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:##67c077;height:8px" />-->
<!--<!--                        <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:#bcd4e6;height:5px" />-->-->
<!--                        <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">-->
<!--                            <div class="row">-->
<!--                                <div class="col-md-12">-->
<!--                                    <h5 class="article-title" itemprop="name">Develop Real-Time Aerial Tracking Algorithms on a Single CPU</h5>-->
<!--                                </div>-->
<!--                                <div class="col-md-12" style="top:10px">-->
<!--                                    <div class="pub-abstract" itemprop="text"><p>Compared to general object tracking, aerial tracking is subjected to more issues like strong motion, mechanical vibration, limited power capacity, etc. Therefore, effective and efficient tracking approaches are desirable in aerial scenarios. I am committed myself to designing robust trackers with real-time frame rates on a single CPU. Finished works adopt novel techniques: (1) repressing aberrance (2) augmenting memory (3) fusing multiple features (4) multi-frame verification (5) multi-resolution strategy (6) part-based method.-->
<!--									                                          <p>Recently, I am working on automatic spatially and temporally attentive correlation filters.  Interestingly, the new method can achieve precise tracking in an automatic learning manner with high efficiency (~60FPS).</p></div></div>-->
<!--                            </div>-->
<!--                        </div>-->
<!--                    </div>-->
<!--					-->
<!--					<div class="col-xs-12">-->
<!--                        <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">-->
<!--                            <div class="row">-->
<!--                                <div class="col-md-12">-->
<!--                                    <h5 class="article-title" itemprop="name">Deep Learning-based Visual Tracking for UAV in Complex Environment</h5>-->
<!--                                </div>-->
<!--                                <div class="col-md-12" style="top:10px">-->
<!--                                    <div class="pub-abstract" itemprop="text"><p>Deep learning has made a remarkable contribution to the development of  computer vision. In visual object tracking community, most deep-based trackers sacrifice speed to pursue robustness and cannot be practically used even with a high-end GPU. Inspired by keyframe-based SLAM, I proposed an efficient deep feature-based tracking framework, i.e., <a href = "https://github.com/vision4robotics/KAOT-tracker">keyfilter-aware object tracker (KAOT)</a>. Intermittent context learning  has significantly lowered redundancy, and keyfilter restriction has smoothly suppressed model corruptions. The tracker runs at around 15 FPS on NVIDIA 2080 GPU and can be used in real-time applications.-->
<!--									                                          <p>Recently, I am focusing on developing lightweight GPU-based trackers with strong robustness based on siamese network to facilitate hardware implementation.</p></div></div>-->
<!--                            </div>-->
<!--                        </div>-->
<!--				    </div>-->
<!--					-->
<!--                    <div class="col-xs-12">-->
<!--                        <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">-->
<!--                            <div class="row">-->
<!--                                <div class="col-md-12">-->
<!--                                    <h5 class="article-title" itemprop="name">Moving Camera Localization in the Indoor and Outdoor Scenarios</h5>-->
<!--                                </div>-->
<!--                                <div class="col-md-12" style="top:10px">-->
<!--                                    <div class="pub-abstract" itemprop="text"><p>Traditional research on intelligent video analytics is primarily based on static cameras, recently, the development of aerial and ground robots leads to new forms of visual sensing based on moving cameras. -->
<!--									                                           The mobile robots with flexibility and autonomy facilitate efficient and effective means of law enforcement, such as building inspection, forest fire monitoring and crowd analysis for large gathering. Various kinds of practical applications of UAV-mounted cameras are-->
<!--																			   meaningful to the establishment of a safe and smart city. I have developed a monocular localization system for moving cameras which is more universal and flexible compared to general localization method like GPS.  -->
<!--																			   In ROS Gazebo, our UAV performs building inspection task in the outdoor scenarios. Besides, this system is validated in the real indoor scenarios on <a href="https://www.quanser.com/products/autonomous-vehicles-research-studio/">quanser</a> platform. </p> -->
<!--									                                          <p>I think that combination of theory and practice is appealing and hardware implementation is crucial to a research.  In the future, I will address both the theoretical and practical perspectives. </p> </div></div>-->
<!--                            </div>-->
<!--                        </div>-->
<!--                    </div>-->
<!--                </div>-->
<!--                </div>-->
<!--            </div>-->
<!--        </section>-->

        <section id="Publications" class="home-section">
            <div class="container">
                <div class="row">
                    <div class="col-xs-12 col-md-6 section-heading">
                        <h1>Publications</h1></div>
                    <div class="col-xs-12">
                        <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:##67c077;height:8px" />
			
			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="/img/headers/disconet.png" style="border:1px solid black" alt="">
				</div>
				<div class="col-md-9">
				<b><font color="black">Learning Distilled Collaboration Graph for Multi-Agent Perception</font></b><br>
				<a href="https://scholar.google.com/citations?user=i_aajNoAAAAJ" target="_blank"><b>Yiming Li</b></a>,
				<a href="">Shunli Ren</a>,
				<a href="https://scholar.google.com/citations?user=MXLs7GcAAAAJ&hl=en" target="_blank">Pengxiang Wu</a>,
				<a href="https://scholar.google.com/citations?user=W_Q33RMAAAAJ&hl=en" target="_blank">Siheng Chen</a>,
				<a href="https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en" target="_blank">Chen Feng</a>,
				<a href="https://www.researchgate.net/profile/Wenjun-Zhang-29" target="_blank">Wenjun Zhang</a>
				<br>
				<b>NeurIPS 2021 
				<a href="" target="_blank"> <small>[Project]</small></a>
				<a href="" target="_blank"> <small>[Paper]</small></a>
				<a href="" target="_blank"> <small>[Code]</small></a> <br></b>
                                <I>"Use knowledge distillation to learn a directed graph with matrix-valued edge weight for multi-agent collaborative perception."</I>
<!--				<b><a href="https://rssvlrr.github.io/" target="_blank">RSS Visual Learning and Reasoning for Robotics Workshop 2021</a></b> <br>-->
				</div>
			</div><hr>		

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="/img/headers/flat.png" style="border:1px solid black" alt="">
				</div>
				<div class="col-md-9">
				<b><font color="black">Fooling LiDAR Perception via Adversarial Trajectory Perturbation</font></b><br>
				<a href="https://scholar.google.com/citations?user=i_aajNoAAAAJ" target="_blank"><b>Yiming Li</b></a>,
				<a href="https://scholar.google.com.hk/citations?user=OTBgvCYAAAAJ&hl=zh-CN" target="_blank">Congcong Wen</a>,
				<a href="https://scholar.google.com/citations?hl=en&user=dgN8vtwAAAAJ&view_op=list_works" target="_blank">Felix Juefei-Xu</a>,
				<a href="https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en" target="_blank">Chen Feng</a>
				<br>
				<b>ICCV 2021, <font color="firebrick">Oral (~3% acceptance rate)</font>
				<a href="https://ai4ce.github.io/FLAT/" target="_blank"> <small>[Project]</small></a>
				<a href="https://arxiv.org/pdf/2103.15326.pdf" target="_blank"> <small>[Paper]</small></a>
				<a href="https://github.com/ai4ce/FLAT" target="_blank"> <small>[Code]</small></a> <br></b>
                                <I>"Adversarial spoofing of a self-driving car's trajectory with small perturbations is enough to jeopardize the LiDAR perception."</I>
<!--				<b><a href="https://rssvlrr.github.io/" target="_blank">RSS Visual Learning and Reasoning for Robotics Workshop 2021</a></b> <br>-->
				</div>
			</div><hr>


			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="/img/headers/hift.png" style="border:1px solid black" alt="">
				</div>
				<div class="col-md-9">
				<b><font color="black">HiFT: Hierarchical Feature Transformer for Aerial Tracking</font></b><br>
				<a href="https://scholar.google.com/citations?user=L9tbNTsAAAAJ&hl=en" target="_blank">Ziang Cao</a>,
                                <a href="https://scholar.google.com/citations?user=zmbMZ4kAAAAJ&hl=en" target="_blank">Changhong Fu</a>,
				<a href="https://scholar.google.com/citations?user=uy-TfXgAAAAJ&hl=en" target="_blank">Junjie Ye</a>,
				<a href="https://scholar.google.com/citations?user=XjZjcakAAAAJ&hl=en" target="_blank">Bowen Li</a>,
				<a href="https://scholar.google.com/citations?user=i_aajNoAAAAJ" target="_blank"><b>Yiming Li</b></a>
				<br>
				<b>ICCV 2021
				<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Cao_HiFT_Hierarchical_Feature_Transformer_for_Aerial_Tracking_ICCV_2021_paper.pdf" target="_blank"> <small>[Paper]</small></a>
				<a href="https://github.com/vision4robotics/HiFT" target="_blank"> <small>[Code]</small></a> <br> </b>
                                <I>"Use a lightweight transformer model to learn a discriminative feature space."</I>
<!--				<b><a href="https://rssvlrr.github.io/" target="_blank">RSS Visual Learning and Reasoning for Robotics Workshop 2021</a></b> <br>-->
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="/img/headers/apn.png" style="border:1px solid black" alt="">
				</div>
				<div class="col-md-9">
				<b><font color="black">Siamese Anchor Proposal Network for High-Speed Aerial Tracking</font></b><br>
                                <a href="https://scholar.google.com/citations?user=zmbMZ4kAAAAJ&hl=en" target="_blank">Changhong Fu</a>,
				<a href="https://scholar.google.com/citations?user=L9tbNTsAAAAJ&hl=en" target="_blank">Ziang Cao</a>,
				<a href="https://scholar.google.com/citations?user=i_aajNoAAAAJ" target="_blank"><b>Yiming Li</b></a>
				<a href="https://scholar.google.com/citations?user=uy-TfXgAAAAJ&hl=en" target="_blank">Junjie Ye</a>,
				<a href="https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en" target="_blank">Chen Feng</a>

				<br>
				<b>ICRA 2021
				<a href="https://arxiv.org/pdf/2012.10706.pdf" target="_blank"> <small>[Paper]</small></a>
				<a href=" https://github.com/vision4robotics/SiamAPN" target="_blank"> <small>[Code]</small></a> <br> </b>
                                <I>"Learn adaptive anchors in siamese tracking to replace pre-defined ones."</I>
<!--				<b><a href="https://rssvlrr.github.io/" target="_blank">RSS Visual Learning and Reasoning for Robotics Workshop 2021</a></b> <br>-->
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="/img/headers/autotrack.png" style="border:1px solid black" alt="">
				</div>
				<div class="col-md-9">
				<b><font color="black">AutoTrack: Towards High-Performance Visual Tracking for UAV with Automatic Spatio-Temporal Regularization</font></b><br>
				<a href="https://scholar.google.com/citations?user=i_aajNoAAAAJ" target="_blank"><b>Yiming Li</b></a>,
                                <a href="https://scholar.google.com/citations?user=zmbMZ4kAAAAJ&hl=en" target="_blank">Changhong Fu</a>,
                                <a href="https://scholar.google.com/citations?user=Ja8dgh8AAAAJ&hl=en" target="_blank">Fangqiang Ding</a>, 
                                <a href="https://scholar.google.com/citations?user=A9D-disAAAAJ&hl=en" target="_blank">Ziyuan Huang</a>,
                                <a href="https://www.researchgate.net/profile/Geng_Lu2" target="_blank">Geng Lu</a>

				<br>
				<b>CVPR 2020
				<a href="https://arxiv.org/pdf/2003.12949.pdf" target="_blank"> <small>[Paper]</small></a>
				<a href="https://github.com/vision4robotics/AutoTrack" target="_blank"> <small>[Code]</small></a> <br> </b>
                                <I>"Our filter learning pipeline can automatically tune spatio-temporal regularization term with response feedback."</I>
<!--				<b><a href="https://rssvlrr.github.io/" target="_blank">RSS Visual Learning and Reasoning for Robotics Workshop 2021</a></b> <br>-->
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="/img/headers/kaot.png" style="border:1px solid black" alt="">
				</div>
				<div class="col-md-9">
				<b><font color="black">Keyfilter-Aware Real-Time UAV Object Tracking</font></b><br>
				<a href="https://scholar.google.com/citations?user=i_aajNoAAAAJ" target="_blank"><b>Yiming Li</b></a>,
                                <a href="https://scholar.google.com/citations?user=zmbMZ4kAAAAJ&hl=en" target="_blank">Changhong Fu</a>,
                                <a href="https://scholar.google.com/citations?user=A9D-disAAAAJ&hl=en" target="_blank">Ziyuan Huang</a>,
                                <a href="https://scholar.google.com/citations?user=qxNq7PQAAAAJ&hl=en" target="_blank">Yinqiang Zhang</a>, 
                                <a href="https://scholar.google.com/citations?user=YYT8-7kAAAAJ&hl=en" target="_blank">Jia Pan</a>

				<br>
				<b>ICRA 2020
				<a href="https://arxiv.org/pdf/2003.05218.pdf" target="_blank"> <small>[Paper]</small></a>
				<a href="https://github.com/vision4robotics/KAOT-tracker" target="_blank"> <small>[Code]</small></a> <br> </b>
                                <I>"Computation redundancy of contextual learning can be largely decreased by keyfilter restriction and intermittent learning strategy."</I>
<!--				<b><a href="https://rssvlrr.github.io/" target="_blank">RSS Visual Learning and Reasoning for Robotics Workshop 2021</a></b> <br>-->
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="/img/headers/AMCF.png" style="border:1px solid black" alt="">
				</div>
				<div class="col-md-9">
				<b><font color="black">Augmented Memory for Correlation Filters in Real-Time UAV Tracking</font></b><br>
				<a href="https://scholar.google.com/citations?user=i_aajNoAAAAJ" target="_blank"><b>Yiming Li</b></a>,
                                <a href="https://scholar.google.com/citations?user=zmbMZ4kAAAAJ&hl=en" target="_blank">Changhong Fu</a>,
                                <a href="https://scholar.google.com/citations?user=Ja8dgh8AAAAJ&hl=en" target="_blank">Fangqiang Ding</a>, 
                                <a href="https://scholar.google.com/citations?user=A9D-disAAAAJ&hl=en" target="_blank">Ziyuan Huang</a>,
                                <a href="https://scholar.google.com/citations?user=YYT8-7kAAAAJ&hl=en" target="_blank">Jia Pan</a>

				<br>
				<b>IROS 2020
				<a href="https://arxiv.org/pdf/1909.10989.pdf" target="_blank"> <small>[Paper]</small></a>
				<a href="https://github.com/vision4robotics/AMCF-tracker" target="_blank"> <small>[Code]</small></a> <br> </b>
                                <I>"Augment the historical information to avoid filter corruptions."</I>
<!--				<b><a href="https://rssvlrr.github.io/" target="_blank">RSS Visual Learning and Reasoning for Robotics Workshop 2021</a></b> <br>-->
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="/img/headers/ARCF.png" style="border:1px solid black" alt="">
				</div>
				<div class="col-md-9">
				<b><font color="black">Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking</font></b><br>
                                <a href="https://scholar.google.com/citations?user=A9D-disAAAAJ&hl=en" target="_blank">Ziyuan Huang</a>,
                                <a href="https://scholar.google.com/citations?user=zmbMZ4kAAAAJ&hl=en" target="_blank">Changhong Fu</a>,
				<a href="https://scholar.google.com/citations?user=i_aajNoAAAAJ" target="_blank"><b>Yiming Li</b></a>,
                                <a href="https://vision4robotics.github.io/authors/fuling-lin/" target="_blank">Fuling Lin</a>, 
                                <a href="https://scholar.google.com/citations?user=ts7ItWgAAAAJ&hl=en" target="_blank">Peng Lu</a>

				<br>
				<b>ICCV 2019
				<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Learning_Aberrance_Repressed_Correlation_Filters_for_Real-Time_UAV_Tracking_ICCV_2019_paper.pdf" target="_blank"> <small>[Paper]</small></a>
				<a href="https://github.com/vision4robotics/ARCF-tracker" target="_blank"> <small>[Code]</small></a> <br> </b>
                                <I>"Penalize the aberrance in the optimization framework."</I>
<!--				<b><a href="https://rssvlrr.github.io/" target="_blank">RSS Visual Learning and Reasoning for Robotics Workshop 2021</a></b> <br>-->
				</div>
			</div><hr>

                    </div>
                </div>
            </div>
        </section>

<!--        <section id="Preprints" class="home-section">-->
<!--            <div class="container">-->
<!--                <div class="row">-->
<!--                    <div class="col-xs-12 col-md-4 section-heading">-->
<!--                        <h1>Preprints</h1></div>-->
<!--                    <div class="col-xs-12">-->
<!--                        <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:#bcd4e6;height:5px" />-->
<!--                        <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">-->
<!--                            <div class="row">-->
<!--                                <div class="col-md-12">-->
<!--                                    <h5 class="article-title" itemprop="name"></h5>-->
<!--                                    <div class="pub-authors" itemprop="author">-->
<!--                                     <b>Yiming Li</b>                                        -->
<!--                                        , <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=zmbMZ4kAAAAJ&view_op=list_works">Changhong Fu</a>, <a href="https://vision4robotics.github.io/authors/fangqiang-ding/">Fangqiang Ding</a>, <a href="https://scholar.google.com.hk/citations?user=A9D-disAAAAJ&hl=zh-CN">Ziyuan Huang</a>, <a href = "https://scholar.google.com.hk/citations?user=YYT8-7kAAAAJ&hl=zh-CN">Jia Pan</a>-->
<!--                                        <a class="btn btn-primary btn-outline btn-xs" href="">PDF</a>-->
<!--				        <a class="btn btn-primary btn-outline btn-xs" href="https://github.com/vision4robotics/AMCF-tracker">CODE</a></div>-->
<!--                                </div>-->
<!--                                <div class="col-md-3" style="top:20px">-->
<!--                                    <img src="/img/headers/AMCF.png" class="pub-banner" itemprop="image" /></div>-->
<!--                                <div class="col-md-8" style="top:10px">-->
<!--                                    <div class="pub-abstract" itemprop="text">In this work, a novel tracker based on DCF framework is proposed to augment memory of previously appeared views while running at real-time speed. Several historical views and the current view are simultaneously introduced in training to allow the tracker to adapt to new appearances as well as memorize previous ones. A novel rapid compressed context learning is proposed to increase the discriminative ability of the filter efficiently.</div></div>-->
<!--                            </div>-->
<!--                        </div>-->
<!--                    </div>-->
<!--                </div>-->
<!--            </div>-->
<!--        </section>-->

	<section id="Patents" class="home-section">
            <div class="container">
                <div class="row">
                    <div class="col-xs-12 col-md-6 section-heading">
                        <h1>Patents</h1></div>
                    <div class="col-xs-12">
                        <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:##67c077;height:8px" />

                        <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                            <div class="row">
                                <div class="col-md-12">
                                    <h5 class="article-title" itemprop="name">UAV-loaded Serpentine Manipulator for Search and Rescue </h5>                                     	
                                <div class="pub-publication">China National Intellectual Property Administration 
								<a class="btn btn-primary btn-outline btn-xs" href="/pdf/UAV-loaded Serpentine Manipulator for Search and Rescue.pdf">PDF</a></div></div>                                
                                <div class="col-md-3" style="top:20px">
                                    <img src="/img/headers/SnakeRobots.png" class="pub-banner" itemprop="image" /></div>
                                <div class="col-md-8" style="top:10px">
                                    <div class="pub-abstract" itemprop="text">We design a UAV-loaded double-headed serpentine manipulator for search and rescue, comprising a multi-rotor drone, an airborne control system, a binocular vision system, a double-headed serpentine robot, and a docking module. The invention solves the problem that the general search and rescue robot can not work in a complicated and narrow environment, and has the advantages of high efficiency.</div></div>
                            </div>
                        </div>

                        <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                            <div class="row">
                                <div class="col-md-12">
                                    <h5 class="article-title" itemprop="name">Magnetic Levitation Positioning Device for Drone's Wireless Charging</h5>                                     	
                                <div class="pub-publication">China National Intellectual Property Administration 
								<a class="btn btn-primary btn-outline btn-xs" href="/pdf/Magnetic Levitation Positioning Device for Drone's Wireless Charging.pdf">PDF</a></div></div>                                
                                <div class="col-md-3" style="top:20px">
                                    <img src="/img/headers/WirelessCharge.png" class="pub-banner" itemprop="image" /></div>
                                <div class="col-md-8" style="top:10px">
                                    <div class="pub-abstract" itemprop="text">We design a magnetic levitation positioning device for charging a drone. The invention realizes autonomous high-efficiency wireless charging of a drone, and has the advantages of high stability, rapidity, high precision, corrosion resistance and long service life.</div></div>
                            </div>
                        </div>


                        <div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                            <div class="row">
                                <div class="col-md-12">
                                    <h5 class="article-title" itemprop="name">Intelligent Base Station System based on Autonomous Flying Camera and Fast Wireless Charging</h5>                                     	
                                <div class="pub-publication">China National Intellectual Property Administration 
								<a class="btn btn-primary btn-outline btn-xs" href="/pdf/Intelligent Base Station System based on Autonomous Flying Camera and Fast Wireless Charging.pdf">PDF</a></div></div>                                
                                <div class="col-md-3" style="top:20px">
                                    <img src="/img/headers/FlyingCamera.png" class="pub-banner" itemprop="image" /></div>
                                <div class="col-md-8" style="top:10px">
                                    <div class="pub-abstract" itemprop="text">We design an intelligent base station system based on autonomous flying camera and fast wireless charging. The system includes flying cameras and a base station, and the base station includes interaction bins for automatic recovery and release of the flying camera, storage bins for flying camera storage and wireless charging, and transport bins for mobile transport of flying cameras in interactive bins and storage bins. Compared with the prior works, our system has various functions, high self-positioning precision and high charging efficiency..</div></div>
                            </div>
                        </div>
						
						<div class="pub-list-item" itemscope="" itemtype="http://schema.org/CreativeWork">
                            <div class="row">
                                <div class="col-md-12">
                                    <h5 class="article-title" itemprop="name">Flying Snake Robot Cooperative Localization based on Online Adaption and Monocular Vision </h5>                                     	
                                <div class="pub-publication">China National Intellectual Property Administration 
								<a class="btn btn-primary btn-outline btn-xs" href="/pdf/Flying Snake Robot Cooperative Localization based on Online Adaption and Monocular Vision.pdf">PDF</a></div></div>                                
                                <!--div class="col-md-3" style="top:20px">
                                    <img src="/img/headers/SnakeRobots.png" class="pub-banner" itemprop="image" /></div-->
                                <div class="col-md-12" style="top:10px">
                                    <div class="pub-abstract" itemprop="text">We develop a flying snake robot cooperative localization method based on online adaption and monocular vision, the method comprises the following steps: (1) constructing a monocular camera acquisition system, (2) acquiring a CAD model of the snake robot, (3) capturing images of onboard snake robot in real time, (4) processing the CAD model, creating a matching template set for each joint, (5) extracting the edge information in the image and matching the joints, (6) calculating the pose of the joint without occlusion in the image according to the optimal matching template, (7) calculating the pose of the remaining joints based on the topological relationships to initialize the pose of each joint, (8) optimizing the pose of each joint. Compared with the prior works, our method has the advantages of low cost, high precision, high speed and adaptability.</div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="Awards" class="home-section">
            <div class="container">
                <div class="row">
                    <div class="col-xs-12 col-md-4 section-heading">
                        <h1>Awards</h1></div>
                    <div class="col-xs-12">
                        <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:##67c077;height:8px" />
<!--                        <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:#bcd4e6;height:5px" />-->
                            <ul class="ul-interests">
                                <li>2021, Hong Kong PhD Fellowship (HKPF) (Declined) </li>
                                <li>2021, HKU Presidential PhD Scholarship (HKU-PS) (Declined) </li>
                                <li>2020, NYU Dean's PhD Fellowship </li>
                                <li>2020, Hirschvogel Excellent Graduation Thesis (1/114) </li>
                                <li>2020, Shanghai Outstanding Graduate (1/114) </li>
                                <li>2019, <b>Academic Stars in TJU (10/18,115)</b></li>
                                <li>2019, <b>Shanghai Scholarship</b> (top 1%)</li>
				<li>2018, Model of Outstanding Students (top 1.5â€°)</li>
				<li>2018, <b>National Scholarship</b> (top 1%)</li>
				<li>2018, Second Prize of the 1st "Energy Intelligence Future" National College Student Innovation and Entrepreneurship Competition</li>
				<li>2018, First Prize of the 3rd Shanghai Mechanics Competition</li>
				<li>2018, First Prize of the 8th Shanghai Innovation Design Competition</li>
				<li>2018, Meritorious Winner in Mathematics Contest in Modeling</li>
				<li>2017, Champion of Honda Eco Mileage Challenge (GS Group)</li>
      
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="Coursework" class="home-section">
            <div class="container">
                <div class="row">
                    <div class="col-xs-12 col-md-4 section-heading">
                        <h1>Coursework</h1></div>
                    <div class="col-xs-12">
                        <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:##67c077;height:8px" />
<!--                        <hr style="filter:alpha(opacity=100,finishopacity=0,style=2);background-color:#bcd4e6;height:5px" />-->
		            <div class="col-md-12">
		                <div class="col-sm-5">
		                    <h3></h3>
		                    <ul class="ul-edu fa-ul">
		                        <li>
		                            <i class="fa-li fa fa-graduation-cap"></i>
		                            <div class="description">
		                                <p class="course">ME-GY-6703
		                                    <br />Linear Control Theory and Design</p>
		                                <p class="institution"><a href="https://scholar.google.ch/citations?hl=en&user=1KQ1VqsAAAAJ">Prof. Maurizio Porfiri</a></p></div>
		                        </li>
		                        <li>
		                            <i class="fa-li fa fa-graduation-cap"></i>
		                            <div class="description">
		                                <p class="course">ROB-GY-6213
		                                    <br />Robot Localization and Navigation</p>
		                                <p class="institution"><a href="https://scholar.google.ch/citations?hl=en&user=W8f0d6oAAAAJ">Prof. Giuseppe Loianno</a></p></div>
		                        </li>
					<li>
		                            <i class="fa-li fa fa-graduation-cap"></i>
		                            <div class="description">
		                                <p class="course">ROB-GY-6323
		                                    <br />Reinforcement Learning and Optimal Control</p>
		                                <p class="institution"><a href="https://scholar.google.ch/citations?hl=en&user=LuA1j4oAAAAJ">Prof. Ludovic Righetti</a></p></div>
		                        </li>
		                    </ul>

		                </div>

				<div class="col-sm-4">
		                    <h3> </h3>
		                    <ul class="ul-edu fa-ul">
		                        <li>
		                            <i class="fa-li fa fa-graduation-cap"></i>
		                            <div class="description">
		                                <p class="course">ROB-GY-6203
		                                    <br />Robot Perception</p>
		                                <p class="institution"><a href="https://scholar.google.ch/citations?user=YeG8ZM0AAAAJ&hl=en">Prof. Chen Feng</a></p></div>
		                        </li>
		                        <li>
		                            <i class="fa-li fa fa-graduation-cap"></i>
		                            <div class="description">
		                                <p class="course">ROB-GY-6333
		                                    <br />Swarm Robotics</p>
		                                <p class="institution"><a href="https://scholar.google.ch/citations?hl=en&user=LuA1j4oAAAAJ">Prof. Ludovic Righetti</a></p></div> 
		                        </li>
		                        <li>
		                            <i class="fa-li fa fa-graduation-cap"></i>
		                            <div class="description">
		                                <p class="course">CSCI-GA-2270
		                                    <br />Computer Graphics</p>
		                                <p class="institution"><a href="https://scholar.google.ch/citations?user=XUp6qhMAAAAJ&hl=en">Prof. Daniele Panozzo</a></p></div>
		                        </li>
		                    </ul>
                        	</div>          

				<div class="col-sm-3">
		                    <h3> </h3>
		                    <ul class="ul-edu fa-ul">
		                        <li>
		                            <i class="fa-li fa fa-graduation-cap"></i>
		                            <div class="description">
		                                <p class="course">ECE-GY-6143
		                                    <br />Machine Learning</p>
		                                <p class="institution"><a href="https://scholar.google.ch/citations?user=YeG8ZM0AAAAJ&hl=en">Prof. Chen Feng</a></p></div>
		                        </li>
		                    </ul>
                        	</div>                   
                        </div>
                    </div>
                </div>
            </div>
        </section>
				
        <section id="contact" class="home-section">
            <div class="container">
                <div class="row">
                    <div class="col-xs-12 col-md-4 section-heading">
                        <h1>Contact</h1></div>
                    <div class="col-xs-12 col-md-8">
                        <ul class="fa-ul">
                            
                            <li>
                                <i class="fa-li fa fa-envelope fa-2x" aria-hidden="true"></i>
                                <span>
                                    yimingli9702@gmail.com</a></span>
                            </li>
                            <li>
                                <i class="fa-li fa fa-phone fa-2x" aria-hidden="true"></i>
                                <span>
                                    (1)917-498-6819</span>
                            </li>
                            <li>
                                <i class="fa-li fa fa-map-marker fa-2x" aria-hidden="true"></i>
                                <span>6 MetroTech Center Brooklyn, NY 11201, USA</span></li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
        <br />
        <footer class="site-footer">
            <div class="container">
                <p class="powered-by">&copy; 2019 Yiming Li &middot; Powered by the
                    <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic theme</a> for
                    <a href="http://gohugo.io" target="_blank">Hugo</a>.
                    <span class="pull-right" aria-hidden="true">
                        <a href="#" id="back_to_top">
                            <span class="button_icon">
                                <i class="fa fa-chevron-up fa-2x"></i></span>
                        </a>
                    </span>
                </p>
            </div>
        </footer>
        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
        <script src="/js/jquery-1.12.3.min.js"></script>
        <script src="/js/bootstrap.min.js"></script>
        <script src="/js/isotope.pkgd.min.js"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.1/imagesloaded.pkgd.min.js"></script>
        <script src="/js/hugo-academic.js"></script-->
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script></body>

</html>
